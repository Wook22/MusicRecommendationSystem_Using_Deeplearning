{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: challenge_set.json\n",
      "Records added from challenge_set.json: 281000\n",
      "Total records loaded: 281000\n",
      "       pid playlist_name                                         track_name  \\\n",
      "0  1000000         Party                                       Little Swing   \n",
      "1  1000000         Party                                   I'm an Albatraoz   \n",
      "2  1000000         Party  Yellow Flicker Beat - From The Hunger Games: M...   \n",
      "3  1000000         Party                                  White Teeth Teens   \n",
      "4  1000000         Party                                               Team   \n",
      "\n",
      "  artist_name           album_name  duration_ms  \\\n",
      "0   AronChupa         Little Swing       163809   \n",
      "1   AronChupa     I'm an Albatraoz       166848   \n",
      "2       Lorde  Yellow Flicker Beat       232506   \n",
      "3       Lorde         Pure Heroine       216600   \n",
      "4       Lorde         Pure Heroine       193058   \n",
      "\n",
      "                              track_uri  \n",
      "0  spotify:track:66U0ASk1VHZsqIkpMjKX3B  \n",
      "1  spotify:track:5MhsZlmKJG6X5kTHkdwC4B  \n",
      "2  spotify:track:0GZoB8h0kqXn7XFm4Sj06k  \n",
      "3  spotify:track:35kahykNu00FPysz3C2euR  \n",
      "4  spotify:track:3G6hD9B2ZHOsgf4WfNu7X1  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Define a function to parse a single JSON file\n",
    "def parse_json(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    playlists = data.get('playlists', [])\n",
    "    records = []\n",
    "    for playlist in playlists:\n",
    "        pid = playlist.get('pid', None)  # Default to None if 'pid' is missing\n",
    "        playlist_name = playlist.get('name', 'Unknown')  # Default to 'Unknown' if 'name' is missing\n",
    "        \n",
    "        # Check if 'tracks' exists and is a list\n",
    "        if not isinstance(playlist.get('tracks'), list):\n",
    "            continue  # Skip this playlist if 'tracks' is missing or not a list\n",
    "        \n",
    "        for track in playlist['tracks']:\n",
    "            # Skip the track if any required field is missing or invalid\n",
    "            if not track.get('track_uri') or not track.get('track_name'):\n",
    "                continue\n",
    "            \n",
    "            # Add the valid track record\n",
    "            records.append({\n",
    "                'pid': pid,\n",
    "                'playlist_name': playlist_name,\n",
    "                'track_name': track.get('track_name', 'Unknown'),\n",
    "                'artist_name': track.get('artist_name', 'Unknown'),\n",
    "                'album_name': track.get('album_name', 'Unknown'),\n",
    "                'duration_ms': track.get('duration_ms', 0),\n",
    "                'track_uri': track.get('track_uri', 'Unknown')\n",
    "            })\n",
    "    return records\n",
    "\n",
    "\n",
    "# Load all JSON files in a directory\n",
    "def load_data_from_directory(directory_path):\n",
    "    all_records = []\n",
    "    for file_name in os.listdir(directory_path):\n",
    "        if file_name.endswith('.json'):\n",
    "            file_path = os.path.join(directory_path, file_name)\n",
    "            print(f\"Processing file: {file_name}\")  # Print statement to check the file being processed\n",
    "            try:\n",
    "                records = parse_json(file_path)\n",
    "                print(f\"Records added from {file_name}: {len(records)}\")  # Print the number of records added\n",
    "                all_records.extend(records)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file_name}: {e}\")  # Log the error\n",
    "    return pd.DataFrame(all_records)\n",
    "\n",
    "\n",
    "# Load the data\n",
    "directory_path = '/Users/wook/Documents/Github/MusicRecommendationSystem_Using_Deeplearning/Data/spotify_million_playlist_dataset_challenge'  # Update with your directory\n",
    "df = load_data_from_directory(directory_path)\n",
    "\n",
    "# Print final DataFrame info and preview\n",
    "print(f\"Total records loaded: {len(df)}\")  # Print the total number of records\n",
    "print(df.head())  # Print the first few rows of the DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Generate TF-IDF vectors for text features\n",
    "def generate_tfidf_features(df, column):\n",
    "    tfidf = TfidfVectorizer(stop_words='english')\n",
    "    tfidf_matrix = tfidf.fit_transform(df[column].fillna(''))\n",
    "    return tfidf_matrix, tfidf\n",
    "\n",
    "# Normalize numerical features\n",
    "def normalize_numeric_feature(df, column):\n",
    "    scaler = MinMaxScaler()\n",
    "    normalized = scaler.fit_transform(df[[column]].fillna(0))\n",
    "    return normalized, scaler\n",
    "\n",
    "# Apply TF-IDF and normalization\n",
    "tfidf_track_name, track_name_vectorizer = generate_tfidf_features(df, 'track_name')\n",
    "tfidf_artist_name, artist_name_vectorizer = generate_tfidf_features(df, 'artist_name')\n",
    "tfidf_album_name, album_name_vectorizer = generate_tfidf_features(df, 'album_name')\n",
    "duration_normalized, duration_scaler = normalize_numeric_feature(df, 'duration_ms')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "\n",
    "# Combine all features into one matrix\n",
    "combined_features = hstack([tfidf_track_name, tfidf_artist_name, tfidf_album_name, duration_normalized])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            pid playlist_name                                track_name  \\\n",
      "6775    1004846       Unknown                              In This Love   \n",
      "93118   1016675    Good vibes                              In This Love   \n",
      "190295  1033675    good vibes         Smokin' Love (feat. Collie Buddz)   \n",
      "93155   1016675    Good vibes         Smokin' Love (feat. Collie Buddz)   \n",
      "93133   1016675    Good vibes                       Fire on the Horizon   \n",
      "190294  1033675    good vibes                          Sound of the Sea   \n",
      "93197   1016675    Good vibes                          Sound of the Sea   \n",
      "24      1000040           bbq                          Sound of the Sea   \n",
      "23      1000040           bbq  Choice Is Yours (feat. Slightly Stoopid)   \n",
      "55186   1007211       Cruisin  Choice Is Yours (feat. Slightly Stoopid)   \n",
      "\n",
      "         artist_name    album_name  duration_ms  \\\n",
      "6775    Stick Figure  Set in Stone       252693   \n",
      "93118   Stick Figure  Set in Stone       252693   \n",
      "190295  Stick Figure  Set in Stone       214206   \n",
      "93155   Stick Figure  Set in Stone       214206   \n",
      "93133   Stick Figure  Set in Stone       327986   \n",
      "190294  Stick Figure  Set in Stone       325480   \n",
      "93197   Stick Figure  Set in Stone       325480   \n",
      "24      Stick Figure  Set in Stone       325480   \n",
      "23      Stick Figure  Set in Stone       305493   \n",
      "55186   Stick Figure  Set in Stone       305493   \n",
      "\n",
      "                                   track_uri  \n",
      "6775    spotify:track:3u1bKblfqeghD3grk3Le2w  \n",
      "93118   spotify:track:3u1bKblfqeghD3grk3Le2w  \n",
      "190295  spotify:track:3D7cUXDEKLAFsoD10QRoiR  \n",
      "93155   spotify:track:3D7cUXDEKLAFsoD10QRoiR  \n",
      "93133   spotify:track:7mnk9W0umx7q4Vo4FjtOot  \n",
      "190294  spotify:track:1Gsv8f8KmowkF5BnfMIGKy  \n",
      "93197   spotify:track:1Gsv8f8KmowkF5BnfMIGKy  \n",
      "24      spotify:track:1Gsv8f8KmowkF5BnfMIGKy  \n",
      "23      spotify:track:1azvKxDb5Vkph2KR7aq1Cx  \n",
      "55186   spotify:track:1azvKxDb5Vkph2KR7aq1Cx  \n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def recommend_tracks(input_track_name, df, combined_features, top_n=10):\n",
    "    # Find the index of the input track\n",
    "    try:\n",
    "        input_idx = df[df['track_name'].str.contains(input_track_name, case=False, na=False)].index[0]\n",
    "    except IndexError:\n",
    "        raise ValueError(f\"Track '{input_track_name}' not found in the dataset.\")\n",
    "\n",
    "    # Convert sparse matrix to a compressed sparse row (CSR) format for row slicing\n",
    "    if not isinstance(combined_features, csr_matrix):\n",
    "        combined_features = csr_matrix(combined_features)\n",
    "    \n",
    "    # Calculate cosine similarity\n",
    "    input_vector = combined_features[input_idx]  # Get the feature vector of the input track\n",
    "    similarity = cosine_similarity(input_vector, combined_features).flatten()  # Calculate similarities\n",
    "\n",
    "    # Get top N similar tracks\n",
    "    top_indices = similarity.argsort()[-top_n-1:-1][::-1]  # Exclude the input track itself\n",
    "    return df.iloc[top_indices]\n",
    "\n",
    "# Example: Recommend tracks similar to \"love\"\n",
    "try:\n",
    "    recommended_tracks = recommend_tracks(\"love\", df, combined_features)\n",
    "    print(recommended_tracks)\n",
    "except ValueError as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>playlist_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>album_name</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>track_uri</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000000</td>\n",
       "      <td>Party</td>\n",
       "      <td>Little Swing</td>\n",
       "      <td>AronChupa</td>\n",
       "      <td>Little Swing</td>\n",
       "      <td>163809</td>\n",
       "      <td>spotify:track:66U0ASk1VHZsqIkpMjKX3B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000000</td>\n",
       "      <td>Party</td>\n",
       "      <td>I'm an Albatraoz</td>\n",
       "      <td>AronChupa</td>\n",
       "      <td>I'm an Albatraoz</td>\n",
       "      <td>166848</td>\n",
       "      <td>spotify:track:5MhsZlmKJG6X5kTHkdwC4B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000000</td>\n",
       "      <td>Party</td>\n",
       "      <td>Yellow Flicker Beat - From The Hunger Games: M...</td>\n",
       "      <td>Lorde</td>\n",
       "      <td>Yellow Flicker Beat</td>\n",
       "      <td>232506</td>\n",
       "      <td>spotify:track:0GZoB8h0kqXn7XFm4Sj06k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000000</td>\n",
       "      <td>Party</td>\n",
       "      <td>White Teeth Teens</td>\n",
       "      <td>Lorde</td>\n",
       "      <td>Pure Heroine</td>\n",
       "      <td>216600</td>\n",
       "      <td>spotify:track:35kahykNu00FPysz3C2euR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000000</td>\n",
       "      <td>Party</td>\n",
       "      <td>Team</td>\n",
       "      <td>Lorde</td>\n",
       "      <td>Pure Heroine</td>\n",
       "      <td>193058</td>\n",
       "      <td>spotify:track:3G6hD9B2ZHOsgf4WfNu7X1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280995</th>\n",
       "      <td>1006767</td>\n",
       "      <td>Playlist 2015</td>\n",
       "      <td>Y No Hago Mas Na' - Reggaeton Mix</td>\n",
       "      <td>El Gran Combo De Puerto Rico</td>\n",
       "      <td>Salsa Classics Revisited</td>\n",
       "      <td>339573</td>\n",
       "      <td>spotify:track:38griAVM808crjbFp9gcPD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280996</th>\n",
       "      <td>1006771</td>\n",
       "      <td>Workout</td>\n",
       "      <td>California Love - Original Version</td>\n",
       "      <td>2Pac</td>\n",
       "      <td>Greatest Hits</td>\n",
       "      <td>285026</td>\n",
       "      <td>spotify:track:1JClFT74TYSXlzpagbmj0S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280997</th>\n",
       "      <td>1006773</td>\n",
       "      <td>Girlz</td>\n",
       "      <td>Intoxicated</td>\n",
       "      <td>Ashley DuBose</td>\n",
       "      <td>Be You</td>\n",
       "      <td>279322</td>\n",
       "      <td>spotify:track:4InLm5a9Qtkru6YxEjM4Qc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280998</th>\n",
       "      <td>1006775</td>\n",
       "      <td>let's get lost</td>\n",
       "      <td>90210 (feat. G-Eazy)</td>\n",
       "      <td>blackbear</td>\n",
       "      <td>Deadroses</td>\n",
       "      <td>223295</td>\n",
       "      <td>spotify:track:4hdog9vyyqG9pcppG2Izek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280999</th>\n",
       "      <td>1006778</td>\n",
       "      <td>Mama</td>\n",
       "      <td>Mama</td>\n",
       "      <td>Jonas Blue</td>\n",
       "      <td>Jonas Blue: Electronic Nature - The Mix 2017</td>\n",
       "      <td>181614</td>\n",
       "      <td>spotify:track:0NiXXAI876aGImAd6rTj8w</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>281000 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            pid   playlist_name  \\\n",
       "0       1000000           Party   \n",
       "1       1000000           Party   \n",
       "2       1000000           Party   \n",
       "3       1000000           Party   \n",
       "4       1000000           Party   \n",
       "...         ...             ...   \n",
       "280995  1006767   Playlist 2015   \n",
       "280996  1006771         Workout   \n",
       "280997  1006773           Girlz   \n",
       "280998  1006775  let's get lost   \n",
       "280999  1006778            Mama   \n",
       "\n",
       "                                               track_name  \\\n",
       "0                                            Little Swing   \n",
       "1                                        I'm an Albatraoz   \n",
       "2       Yellow Flicker Beat - From The Hunger Games: M...   \n",
       "3                                       White Teeth Teens   \n",
       "4                                                    Team   \n",
       "...                                                   ...   \n",
       "280995                  Y No Hago Mas Na' - Reggaeton Mix   \n",
       "280996                 California Love - Original Version   \n",
       "280997                                        Intoxicated   \n",
       "280998                               90210 (feat. G-Eazy)   \n",
       "280999                                               Mama   \n",
       "\n",
       "                         artist_name  \\\n",
       "0                          AronChupa   \n",
       "1                          AronChupa   \n",
       "2                              Lorde   \n",
       "3                              Lorde   \n",
       "4                              Lorde   \n",
       "...                              ...   \n",
       "280995  El Gran Combo De Puerto Rico   \n",
       "280996                          2Pac   \n",
       "280997                 Ashley DuBose   \n",
       "280998                     blackbear   \n",
       "280999                    Jonas Blue   \n",
       "\n",
       "                                          album_name  duration_ms  \\\n",
       "0                                       Little Swing       163809   \n",
       "1                                   I'm an Albatraoz       166848   \n",
       "2                                Yellow Flicker Beat       232506   \n",
       "3                                       Pure Heroine       216600   \n",
       "4                                       Pure Heroine       193058   \n",
       "...                                              ...          ...   \n",
       "280995                      Salsa Classics Revisited       339573   \n",
       "280996                                 Greatest Hits       285026   \n",
       "280997                                        Be You       279322   \n",
       "280998                                     Deadroses       223295   \n",
       "280999  Jonas Blue: Electronic Nature - The Mix 2017       181614   \n",
       "\n",
       "                                   track_uri  \n",
       "0       spotify:track:66U0ASk1VHZsqIkpMjKX3B  \n",
       "1       spotify:track:5MhsZlmKJG6X5kTHkdwC4B  \n",
       "2       spotify:track:0GZoB8h0kqXn7XFm4Sj06k  \n",
       "3       spotify:track:35kahykNu00FPysz3C2euR  \n",
       "4       spotify:track:3G6hD9B2ZHOsgf4WfNu7X1  \n",
       "...                                      ...  \n",
       "280995  spotify:track:38griAVM808crjbFp9gcPD  \n",
       "280996  spotify:track:1JClFT74TYSXlzpagbmj0S  \n",
       "280997  spotify:track:4InLm5a9Qtkru6YxEjM4Qc  \n",
       "280998  spotify:track:4hdog9vyyqG9pcppG2Izek  \n",
       "280999  spotify:track:0NiXXAI876aGImAd6rTj8w  \n",
       "\n",
       "[281000 rows x 7 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def create_training_data_optimized(df, max_pairs_per_playlist=100, max_negative_samples=None):\n",
    "    positive_samples = []\n",
    "    negative_samples = []\n",
    "\n",
    "    # Positive pairs with limited sampling\n",
    "    for pid, group in df.groupby('pid'):\n",
    "        tracks = group['track_uri'].tolist()\n",
    "        \n",
    "        # Generate all possible pairs\n",
    "        if len(tracks) > 1:\n",
    "            pairs = np.array(np.triu_indices(len(tracks), k=1)).T\n",
    "            np.random.shuffle(pairs)  # Randomize the pairs\n",
    "            \n",
    "            # Limit to max pairs per playlist\n",
    "            if len(pairs) > max_pairs_per_playlist:\n",
    "                pairs = pairs[:max_pairs_per_playlist]\n",
    "\n",
    "            positive_samples.extend([(tracks[p[0]], tracks[p[1]], 1) for p in pairs])\n",
    "\n",
    "    # Create a single array of all unique tracks\n",
    "    all_tracks = df['track_uri'].unique()\n",
    "    num_positive_samples = len(positive_samples)\n",
    "    num_negative_samples = max_negative_samples if max_negative_samples else num_positive_samples\n",
    "\n",
    "    # Generate negative pairs via efficient random sampling\n",
    "    negative_samples = [\n",
    "        (all_tracks[i], all_tracks[j], 0)\n",
    "        for i, j in zip(\n",
    "            np.random.randint(0, len(all_tracks), num_negative_samples),\n",
    "            np.random.randint(0, len(all_tracks), num_negative_samples),\n",
    "        )\n",
    "        if i != j  # Ensure the pair isn't the same track\n",
    "    ]\n",
    "\n",
    "    # Combine positive and negative samples\n",
    "    samples = positive_samples + negative_samples\n",
    "    return pd.DataFrame(samples, columns=['track1', 'track2', 'label'])\n",
    "\n",
    "# Call the function with a DataFrame\n",
    "samples_df = create_training_data_optimized(df, max_pairs_per_playlist=100, max_negative_samples=50000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Feature Matrix\n",
    "def create_feature_matrix(df, tfidf_vectorizer):\n",
    "    track_features = {}\n",
    "    metadata = df[['track_uri', 'track_name', 'artist_name', 'album_name', 'duration_ms']]\n",
    "\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(metadata['track_name'].fillna(''))\n",
    "    for i, row in metadata.iterrows():\n",
    "        track_features[row['track_uri']] = np.concatenate([\n",
    "            tfidf_matrix[i].toarray().flatten(),\n",
    "            [row['duration_ms'] / 100000]\n",
    "        ])\n",
    "    return track_features\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=100)\n",
    "track_features = create_feature_matrix(df, tfidf_vectorizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(samples_df, track_features):\n",
    "    features = []\n",
    "    for _, row in samples_df.iterrows():\n",
    "        track1_features = track_features.get(row['track1'], np.zeros(101))\n",
    "        track2_features = track_features.get(row['track2'], np.zeros(101))\n",
    "        features.append(np.concatenate([track1_features, track2_features]))\n",
    "    return np.array(features)\n",
    "\n",
    "X = generate_features(samples_df, track_features)\n",
    "y = samples_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9107142857142857\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Dimensionality reduction\n",
    "pca = PCA(n_components=50)\n",
    "X_reduced = pca.fit_transform(X)\n",
    "\n",
    "# Stratified train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_reduced, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Train the model with parallelization\n",
    "model = RandomForestClassifier(n_estimators=50, max_depth=10, random_state=42, n_jobs=-1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy_rf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [00:32:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9108035714285714\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Train Model using XGBoost\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=100,    # Number of boosting rounds\n",
    "    max_depth=6,         # Maximum depth of a tree\n",
    "    learning_rate=0.1,   # Step size shrinkage\n",
    "    random_state=42,     # Reproducibility\n",
    "    use_label_encoder=False,  # Avoid warning in recent versions of XGBoost\n",
    "    eval_metric=\"logloss\"     # Loss metric for binary classification\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the Model\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy_xgb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC\n",
    "\n",
    "# # Train Model using Support Vector Machine\n",
    "# svm_model = SVC(kernel='rbf', probability=True, random_state=42)  # Use RBF kernel for non-linear separation\n",
    "# svm_model.fit(X_train, y_train)\n",
    "\n",
    "# # Evaluate the Model\n",
    "# y_pred = svm_model.predict(X_test)\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(f\"SVM Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.9107142857142857\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Train Model using Logistic Regression\n",
    "logistic_model = LogisticRegression(max_iter=500, random_state=42)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the Model\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "accuracy_lr = accuracy_score(y_test, y_pred)\n",
    "print(f\"Logistic Regression Accuracy: {accuracy_lr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make Recommendations\n",
    "# def recommend_similar_tracks(input_track_uri, track_features, model, df, top_n=10):\n",
    "#     input_features = track_features.get(input_track_uri, np.zeros(101))\n",
    "#     candidates = df['track_uri'].unique()\n",
    "\n",
    "#     scores = []\n",
    "#     for candidate in candidates:\n",
    "#         candidate_features = track_features.get(candidate, np.zeros(101))\n",
    "#         pair_features = np.concatenate([input_features, candidate_features])\n",
    "#         score = model.predict_proba([pair_features])[0][1]\n",
    "#         scores.append((candidate, score))\n",
    "\n",
    "#     scores = sorted(scores, key=lambda x: x[1], reverse=True)[:top_n]\n",
    "#     recommended_tracks = [df[df['track_uri'] == track]['track_name'].values[0] for track, _ in scores]\n",
    "#     return recommended_tracks\n",
    "\n",
    "# # Example usage\n",
    "# input_track_uri = \"spotify:track:1jNNHFZmRGXZFHlil5uhei\"  # Replace with actual URI\n",
    "# recommendations = recommend_similar_tracks(input_track_uri, track_features, model, df)\n",
    "# print(\"Recommended Tracks:\", recommendations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
